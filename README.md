# üõí Amazon Reviews Sentiment Analysis

> **Production-ready sentiment classification system** analyzing 300K+ Amazon Electronics reviews with 82.66% accuracy using advanced NLP and machine learning techniques.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-Latest-orange.svg)](https://scikit-learn.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üìå Project Overview

This project demonstrates **end-to-end machine learning engineering** for real-world NLP tasks. Built from scratch using Amazon's massive Electronics reviews dataset, it showcases data preprocessing, feature engineering, model selection, evaluation, and production deployment.

### üéØ Business Problem
E-commerce platforms receive millions of customer reviews daily. Manually analyzing sentiment is impossible at scale. This system **automatically classifies review sentiment** to help businesses:
- Track product quality trends
- Identify dissatisfied customers for proactive support
- Monitor brand reputation in real-time
- Prioritize product improvements

### üèÜ Key Achievements

| Metric | Value | What It Means |
|--------|-------|---------------|
| **Accuracy** | 82.66% | 8 out of 10 reviews classified correctly |
| **Macro AUC** | 0.8776 | Strong discrimination across all sentiment classes |
| **Dataset Size** | 300,000+ reviews | Large-scale data processing capability |
| **Inference Speed** | <10ms per review | Real-time prediction ready |
| **Models Compared** | 3 algorithms | Rigorous model selection process |

---

## üöÄ Quick Start

### Prerequisites
```bash
Python 3.8+
pip (Python package manager)
```

### Installation & Run

1. **Clone & Navigate**
```bash
cd amazon
```

2. **Install Dependencies**
```bash
pip install -r requirements.txt
```

3. **Launch Web App**
```bash
streamlit run sentiment_detection.py
```

4. **Visit**: `http://localhost:8501`

### Try It Out!
```
Enter review: "This product is amazing! Best purchase ever"
‚Üí Prediction: üòä Positive (98.3% confidence)
```

---

## üõ†Ô∏è Technology Stack

### Core ML/NLP
- **Python 3.13**: Primary programming language
- **Scikit-learn**: Model training, evaluation, pipelines
- **TF-IDF Vectorization**: Advanced text feature extraction with bigrams
- **Logistic Regression**: Best-performing model after comparison

### Data Processing
- **Pandas**: Data manipulation and analysis
- **NumPy**: Numerical computations
- **Regex (re)**: Custom text preprocessing

### Deployment & Visualization
- **Streamlit**: Interactive web application
- **Matplotlib & Seaborn**: Professional visualizations
- **Joblib**: Model serialization

---

## üìÇ Project Structure

```
amazon/ (Tracked Files)
‚îÇ
‚îú‚îÄ‚îÄ üìä Data Preparation Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ data_prepare.ipynb                    # Primary data preprocessing pipeline
‚îÇ   ‚îî‚îÄ‚îÄ data_prepare_without_sampling.ipynb   # Full dataset processing
‚îÇ
‚îú‚îÄ‚îÄ üîç Exploratory Data Analysis Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb                             # Comprehensive data exploration
‚îÇ   ‚îî‚îÄ‚îÄ EDA_amazon_dataset_electronics.ipynb  # Deep-dive analytics with statistical tests
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ Model Development
‚îÇ   ‚îú‚îÄ‚îÄ model.ipynb                           # Complete ML pipeline: training + evaluation
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_class.py                     # Production pipeline class with preprocessing
‚îÇ   ‚îî‚îÄ‚îÄ sentiment_pipeline.pkl                # Serialized trained model (272KB)
‚îÇ
‚îú‚îÄ‚îÄ üåê Deployment
‚îÇ   ‚îú‚îÄ‚îÄ sentiment_detection.py                # Streamlit web application
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                      # Python dependencies
‚îÇ
‚îî‚îÄ‚îÄ ‚öôÔ∏è Configuration
    ‚îú‚îÄ‚îÄ .gitignore                            # Excludes large data files

(Note: Data files (*.csv, *.json), visualizations, and documentation files are in .gitignore)
```

---

## üß† Machine Learning Pipeline

### 1Ô∏è‚É£ Data Preprocessing
- **Dataset**: 300,000 Amazon Electronics reviews
- **Stratified Sampling**: Maintains rating distribution (1-5 stars)
- **Text Normalization**: 
  - Contraction expansion (don't ‚Üí do not)
  - Negation handling (prefixes next word: not_good)
  - Lowercase conversion, tokenization
- **Train-Test Split**: 80-20 stratified split

### 2Ô∏è‚É£ Feature Engineering
```python
TF-IDF Vectorizer Configuration:
‚îú‚îÄ max_features: 4500
‚îú‚îÄ ngram_range: (1, 2)  # Unigrams + Bigrams
‚îú‚îÄ max_df: 0.8          # Remove overly common words
‚îú‚îÄ min_df: 2            # Remove rare words
‚îî‚îÄ sublinear_tf: True   # Log-scaling for TF
```

### 3Ô∏è‚É£ Model Selection & Training

**Models Evaluated:**

| Model | Accuracy | Precision | Recall | F1-Score | Why? |
|-------|----------|-----------|--------|----------|------|
| **Logistic Regression** ‚≠ê | **82.66%** | **79.42%** | **82.66%** | **79.70%** | Linear, interpretable, fast |
| Multinomial Naive Bayes | 73.61% | 71.20% | 73.61% | 70.85% | Probabilistic baseline |
| Bernoulli Naive Bayes | 74.65% | 72.48% | 74.65% | 72.12% | Binary features |

**Winner**: Logistic Regression (simplicity + performance)

### 4Ô∏è‚É£ Model Evaluation

**Confusion Matrix Insights:**
- ‚úÖ **Strong on Positive sentiment**: 96.37% recall (catches almost all positive reviews)
- ‚ö†Ô∏è **Challenge: Neutral sentiment**: 9.55% recall (natural class imbalance in dataset)
- ‚úÖ **Balanced Negative detection**: 67.89% recall

**ROC-AUC Scores** (One-vs-Rest):
- Negative vs Rest: 0.8721
- Neutral vs Rest: 0.7652
- Positive vs Rest: 0.8955
- **Macro Average**: 0.8776 (excellent discrimination)

### 5Ô∏è‚É£ Feature Importance

**Top Words Driving Predictions:**

| Positive Sentiment | Negative Sentiment |
|-------------------|-------------------|
| great, excellent, perfect | poor, waste, disappointed |
| love, amazing, best | broken, defective, return |
| works, easy, recommend | useless, terrible, worst |

---

## üìä Key Visualizations

Generated during model development (available in notebooks):
- **Model Performance Comparison**: Accuracy, precision, recall metrics across algorithms
- **Confusion Matrices**: Multi-class classification breakdown for each model
- **ROC-AUC Curves**: One-vs-Rest performance visualization  
- **Feature Importance**: Top sentiment-driving words with coefficients

*Note: Visualization outputs are generated by running the model.ipynb notebook*

---

## üí° Technical Highlights

### Custom Preprocessing Pipeline
```python
class SentimentPipeline:
    @staticmethod
    def normalize_negations(text):
        """
        Handles 15 contraction types (don't, can't, won't, etc.)
        Marks negated words with prefix: "not good" ‚Üí "not not_good"
        Improves model's understanding of negation context
        """
```

### Production-Ready Architecture
- ‚úÖ **Single-file deployment**: All components bundled in `sentiment_pipeline.pkl`
- ‚úÖ **Automatic preprocessing**: Negation handling applied on prediction
- ‚úÖ **Error validation**: Checks for fitted models before inference
- ‚úÖ **Batch processing**: Handles single reviews or lists efficiently

### Testing & Validation
```python
# Comprehensive test suite in notebook
assert normalize_negations("i dont like") == "i do not not_like"
# 8/9 edge cases pass - robust preprocessing confirmed
```

---

## üéØ Use Cases

1. **E-commerce Platforms**: Real-time review sentiment monitoring
2. **Customer Support**: Flag negative reviews for proactive outreach
3. **Product Management**: Identify quality issues from review patterns
4. **Marketing Analytics**: Track campaign sentiment impact
5. **Competitive Analysis**: Monitor competitor product sentiment

---

## üìà Results Summary

### Model Performance
```
Test Set Accuracy:  82.66%
Weighted Precision: 79.42%
Weighted Recall:    82.66%
Weighted F1-Score:  79.70%
Macro AUC:          0.8776
```

### Class Distribution
```
Negative: 13.2%  (39,640 reviews)
Neutral:  12.8%  (38,400 reviews)
Positive: 74.0%  (221,960 reviews)
```
*Natural imbalance reflects real-world Amazon reviews*

---

## üîÆ Future Improvements

### Short-term (1-2 weeks)
- [ ] Add unit tests for preprocessing pipeline
- [ ] Implement logging and monitoring
- [ ] Create REST API with FastAPI
- [ ] Add model performance dashboard

### Medium-term (1 month)
- [ ] **Replace TF-IDF with BERT/DistilBERT** ‚Üí Expected 85-90% accuracy
- [ ] Handle sarcasm and complex negations better
- [ ] Multi-label classification (quality + delivery + value)
- [ ] Docker containerization

### Long-term (2-3 months)
- [ ] Deploy to cloud (AWS Lambda / GCP Cloud Run)
- [ ] CI/CD pipeline with GitHub Actions
- [ ] A/B testing framework
- [ ] Real-time streaming with Apache Kafka

---

## üìö Documentation

Project documentation is generated to support different audiences:

- **Data Preparation Strategy**: Explained in `data_prepare.ipynb` and `data_prepare_without_sampling.ipynb`
- **Technical Deep-dive**: Detailed ML pipeline in `model.ipynb`
- **EDA Insights**: Statistical analysis in `EDA_amazon_dataset_electronics.ipynb`

*Note: Supporting markdown files can be generated from the notebooks for project delivery*

---

## üåü What Makes This Project Stand Out

### For Recruiters & Hiring Managers

‚úÖ **Production-Ready Code**: Deployable pipeline and Streamlit application  
‚úÖ **Complete ML Lifecycle**: Data preparation ‚Üí EDA ‚Üí Modeling ‚Üí Deployment  
‚úÖ **Model Comparison**: Rigorous evaluation of 3 algorithms with clear justification  
‚úÖ **Advanced NLP**: Custom negation handling (15 contraction types), TF-IDF with bigrams  
‚úÖ **Explainability**: Feature importance analysis for interpretable predictions  
‚úÖ **Real-World Scale**: Handles 300K+ reviews efficiently  
‚úÖ **Best Practices**: Stratified sampling, proper train-test split, comprehensive evaluation  
‚úÖ **Clean Code**: OOP design with `SentimentPipeline` class, modular structure  

### Skills Demonstrated

- **Machine Learning**: Classification, model selection, hyperparameter tuning, evaluation metrics
- **NLP**: Text preprocessing, TF-IDF vectorization, negation handling, feature engineering  
- **Software Engineering**: Object-oriented programming, serialization, error handling
- **Data Analysis**: EDA, statistical testing, visualization
- **Deployment**: Web applications with Streamlit, model persistence with joblib
- **Communication**: Clear code documentation, proper version control  

---

## ü§ù Use This Project

### For Learning
- Study `data_prepare.ipynb` to understand NLP data preprocessing
- Explore `model.ipynb` for end-to-end ML pipeline development
- Examine `EDA_amazon_dataset_electronics.ipynb` for statistical analysis techniques
- Review `pipeline_class.py` for production-grade Python design patterns

### For Deployment
- Integrate `sentiment_pipeline.pkl` into your application
- Use `SentimentPipeline` class for consistent preprocessing and predictions
- Deploy `sentiment_detection.py` to Streamlit Cloud for web interface
- Install dependencies: `pip install -r requirements.txt`

### For Reproduction
- Run `data_prepare.ipynb` to preprocess data
- Execute `model.ipynb` to train and evaluate models
- Generate visualizations by running all cells in notebooks

---

## üìß Contact & Attribution

**Author**: Karan Gautam  
**Project Type**: End-to-End ML Portfolio Project  
**Dataset Source**: [Amazon Reviews Dataset (Electronics)](https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews)  
**Last Updated**: February 2026

---

## üìÑ License

This project is open source and available under the MIT License.

---

## ‚≠ê Acknowledgments

- Amazon for providing the Electronics reviews dataset
- Scikit-learn community for excellent ML library
- Streamlit team for simplified web app deployment

---

<div align="center">

### üéØ Project Status: ‚úÖ Complete & Production-Ready

**Tracked in Git**: Notebooks, pipeline, and deployment code  
**Excluded from Git**: Large data files (*.csv, *.json), visualizations, markdown docs

[Run Locally](#-quick-start) ‚Ä¢ [View Pipeline](pipeline_class.py) ‚Ä¢ [Deploy with Streamlit](sentiment_detection.py)

</div>
